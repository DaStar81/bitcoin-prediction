{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shampoo-bitcoin-lstm.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2uzO3RWzGSAf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "608995a9-1c87-4a46-efb8-0284767e879d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531734234296,
          "user_tz": -420,
          "elapsed": 19471,
          "user": {
            "displayName": "Kris Buote",
            "photoUrl": "//lh3.googleusercontent.com/-bziZzyzq0qE/AAAAAAAAAAI/AAAAAAAABbM/c96Ao13zmFM/s50-c-k-no/photo.jpg",
            "userId": "103737311338281434573"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Upload shampoo-sales.csv\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d435c308-4431-4eeb-9eae-782ffa0e5dba\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d435c308-4431-4eeb-9eae-782ffa0e5dba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving BitcoinDayPrice_April2013-June2018.npy to BitcoinDayPrice_April2013-June2018 (2).npy\n",
            "User uploaded file \"BitcoinDayPrice_April2013-June2018.npy\" with length 30368 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kHuU_OSjH1H7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM Network and Data Preprocessing\n"
      ]
    },
    {
      "metadata": {
        "id": "nj3FrKUAHaGg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LSTM for shampoo sales prediction tutorial: \n",
        "(https://)https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
        "\n",
        "Data: https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv\n"
      ]
    },
    {
      "metadata": {
        "id": "l4lZGw3Imhdk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "from pandas import concat\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "import numpy\n",
        "\n",
        "# date-time parsing function for loading the dataset\n",
        "def parser(x):\n",
        "  return datetime.strptime('190'+x, '%Y-%m')\n",
        "\n",
        "# frame a sequence as a supervised learning problem\n",
        "def timeseries_to_supervised(data, lag=10):\n",
        "  df = DataFrame(data)\n",
        "  columns = [df.shift(i) for i in range(1, lag+1)]\n",
        "  columns.append(df)\n",
        "  df = concat(columns, axis=1)\n",
        "  df.fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "  diff = list()\n",
        "  for i in range(interval, len(dataset)):\n",
        "    value = dataset[i] - dataset[i - interval]\n",
        "    diff.append(value)\n",
        "  return Series(diff)\n",
        "\n",
        "# invert differenced value\n",
        "def inverse_difference(history, yhat, interval=1):\n",
        "  return yhat + history[-interval]\n",
        "\n",
        "# scale train and test data to [-1, 1]\n",
        "def scale(train, test):\n",
        "  # fit scaler\n",
        "  scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "  scaler = scaler.fit(train)\n",
        "  # transform train\n",
        "  train = train.reshape(train.shape[0], train.shape[1])\n",
        "  train_scaled = scaler.transform(train)\n",
        "  # transform test\n",
        "  test = test.reshape(test.shape[0], test.shape[1])\n",
        "  test_scaled = scaler.transform(test)\n",
        "  return scaler, train_scaled, test_scaled\n",
        "\n",
        "# inverse scaling for a forecasted value\n",
        "def invert_scale(scaler, X, value):\n",
        "  new_row = [x for x in X] + [value]\n",
        "  array = numpy.array(new_row)\n",
        "  array = array.reshape(1, len(array))\n",
        "  inverted = scaler.inverse_transform(array)\n",
        "  return inverted[0, -1]\n",
        "\n",
        "# fit an LSTM network to training data\n",
        "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
        "  X, y = train[:, 0:-1], train[:, -1]\n",
        "  X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  for i in range(nb_epoch):\n",
        "    model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "    model.reset_states()\n",
        "    print('Epoch ' + str(i) + ' complete')\n",
        "  return model\n",
        "\n",
        "# make a one-step forecast\n",
        "def forecast_lstm(model, batch_size, X):\n",
        "  X = X.reshape(1, 1, len(X))\n",
        "  yhat = model.predict(X, batch_size=batch_size)\n",
        "  return yhat[0,0]\n",
        "\n",
        "# load dataset\n",
        "series = numpy.load('BitcoinDayPrice_April2013-June2018.npy')\n",
        "raw_values = series[:,1]\n",
        "\n",
        "# series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "            \n",
        "# transform data to be stationary\n",
        "# raw_values = series.values\n",
        "\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "# transform data to be supervised learning\n",
        "supervised = timeseries_to_supervised(diff_values, 1)\n",
        "supervised_values = supervised.values\n",
        "\n",
        "# split data into train and test-sets\n",
        "train_length = int((0.99*supervised_values.shape[0])) #Train on 99% of data\n",
        "train, test = supervised_values[0:train_length], supervised_values[train_length:]\n",
        "\n",
        "# transform the scale of the data\n",
        "scaler, train_scaled, test_scaled = scale(train, test)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdyoqCLXCCfR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ]
    },
    {
      "metadata": {
        "id": "BWIYDkZrBjbc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3536
        },
        "outputId": "10eeacb6-4f8a-48a1-f728-0b71afea1a3d"
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "lstm_model = fit_lstm(train_scaled, 1, 500, 1000) #input: scaled training data, batch)size, # epochs, # neurons in hidden layer\n",
        "# forecast the entire training dataset to build up state for forecasting\n",
        "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
        "lstm_model.predict(train_reshaped, batch_size=1)\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 complete\n",
            "Epoch 1 complete\n",
            "Epoch 2 complete\n",
            "Epoch 3 complete\n",
            "Epoch 4 complete\n",
            "Epoch 5 complete\n",
            "Epoch 6 complete\n",
            "Epoch 7 complete\n",
            "Epoch 8 complete\n",
            "Epoch 9 complete\n",
            "Epoch 10 complete\n",
            "Epoch 11 complete\n",
            "Epoch 12 complete\n",
            "Epoch 13 complete\n",
            "Epoch 14 complete\n",
            "Epoch 15 complete\n",
            "Epoch 16 complete\n",
            "Epoch 17 complete\n",
            "Epoch 18 complete\n",
            "Epoch 19 complete\n",
            "Epoch 20 complete\n",
            "Epoch 21 complete\n",
            "Epoch 22 complete\n",
            "Epoch 23 complete\n",
            "Epoch 24 complete\n",
            "Epoch 25 complete\n",
            "Epoch 26 complete\n",
            "Epoch 27 complete\n",
            "Epoch 28 complete\n",
            "Epoch 29 complete\n",
            "Epoch 30 complete\n",
            "Epoch 31 complete\n",
            "Epoch 32 complete\n",
            "Epoch 33 complete\n",
            "Epoch 34 complete\n",
            "Epoch 35 complete\n",
            "Epoch 36 complete\n",
            "Epoch 37 complete\n",
            "Epoch 38 complete\n",
            "Epoch 39 complete\n",
            "Epoch 40 complete\n",
            "Epoch 41 complete\n",
            "Epoch 42 complete\n",
            "Epoch 43 complete\n",
            "Epoch 44 complete\n",
            "Epoch 45 complete\n",
            "Epoch 46 complete\n",
            "Epoch 47 complete\n",
            "Epoch 48 complete\n",
            "Epoch 49 complete\n",
            "Epoch 50 complete\n",
            "Epoch 51 complete\n",
            "Epoch 52 complete\n",
            "Epoch 53 complete\n",
            "Epoch 54 complete\n",
            "Epoch 55 complete\n",
            "Epoch 56 complete\n",
            "Epoch 57 complete\n",
            "Epoch 58 complete\n",
            "Epoch 59 complete\n",
            "Epoch 60 complete\n",
            "Epoch 61 complete\n",
            "Epoch 62 complete\n",
            "Epoch 63 complete\n",
            "Epoch 64 complete\n",
            "Epoch 65 complete\n",
            "Epoch 66 complete\n",
            "Epoch 67 complete\n",
            "Epoch 68 complete\n",
            "Epoch 69 complete\n",
            "Epoch 70 complete\n",
            "Epoch 71 complete\n",
            "Epoch 72 complete\n",
            "Epoch 73 complete\n",
            "Epoch 74 complete\n",
            "Epoch 75 complete\n",
            "Epoch 76 complete\n",
            "Epoch 77 complete\n",
            "Epoch 78 complete\n",
            "Epoch 79 complete\n",
            "Epoch 80 complete\n",
            "Epoch 81 complete\n",
            "Epoch 82 complete\n",
            "Epoch 83 complete\n",
            "Epoch 84 complete\n",
            "Epoch 85 complete\n",
            "Epoch 86 complete\n",
            "Epoch 87 complete\n",
            "Epoch 88 complete\n",
            "Epoch 89 complete\n",
            "Epoch 90 complete\n",
            "Epoch 91 complete\n",
            "Epoch 92 complete\n",
            "Epoch 93 complete\n",
            "Epoch 94 complete\n",
            "Epoch 95 complete\n",
            "Epoch 96 complete\n",
            "Epoch 97 complete\n",
            "Epoch 98 complete\n",
            "Epoch 99 complete\n",
            "Epoch 100 complete\n",
            "Epoch 101 complete\n",
            "Epoch 102 complete\n",
            "Epoch 103 complete\n",
            "Epoch 104 complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 105 complete\n",
            "Epoch 106 complete\n",
            "Epoch 107 complete\n",
            "Epoch 108 complete\n",
            "Epoch 109 complete\n",
            "Epoch 110 complete\n",
            "Epoch 111 complete\n",
            "Epoch 112 complete\n",
            "Epoch 113 complete\n",
            "Epoch 114 complete\n",
            "Epoch 115 complete\n",
            "Epoch 116 complete\n",
            "Epoch 117 complete\n",
            "Epoch 118 complete\n",
            "Epoch 119 complete\n",
            "Epoch 120 complete\n",
            "Epoch 121 complete\n",
            "Epoch 122 complete\n",
            "Epoch 123 complete\n",
            "Epoch 124 complete\n",
            "Epoch 125 complete\n",
            "Epoch 126 complete\n",
            "Epoch 127 complete\n",
            "Epoch 128 complete\n",
            "Epoch 129 complete\n",
            "Epoch 130 complete\n",
            "Epoch 131 complete\n",
            "Epoch 132 complete\n",
            "Epoch 133 complete\n",
            "Epoch 134 complete\n",
            "Epoch 135 complete\n",
            "Epoch 136 complete\n",
            "Epoch 137 complete\n",
            "Epoch 138 complete\n",
            "Epoch 139 complete\n",
            "Epoch 140 complete\n",
            "Epoch 141 complete\n",
            "Epoch 142 complete\n",
            "Epoch 143 complete\n",
            "Epoch 144 complete\n",
            "Epoch 145 complete\n",
            "Epoch 146 complete\n",
            "Epoch 147 complete\n",
            "Epoch 148 complete\n",
            "Epoch 149 complete\n",
            "Epoch 150 complete\n",
            "Epoch 151 complete\n",
            "Epoch 152 complete\n",
            "Epoch 153 complete\n",
            "Epoch 154 complete\n",
            "Epoch 155 complete\n",
            "Epoch 156 complete\n",
            "Epoch 157 complete\n",
            "Epoch 158 complete\n",
            "Epoch 159 complete\n",
            "Epoch 160 complete\n",
            "Epoch 161 complete\n",
            "Epoch 162 complete\n",
            "Epoch 163 complete\n",
            "Epoch 164 complete\n",
            "Epoch 165 complete\n",
            "Epoch 166 complete\n",
            "Epoch 167 complete\n",
            "Epoch 168 complete\n",
            "Epoch 169 complete\n",
            "Epoch 170 complete\n",
            "Epoch 171 complete\n",
            "Epoch 172 complete\n",
            "Epoch 173 complete\n",
            "Epoch 174 complete\n",
            "Epoch 175 complete\n",
            "Epoch 176 complete\n",
            "Epoch 177 complete\n",
            "Epoch 178 complete\n",
            "Epoch 179 complete\n",
            "Epoch 180 complete\n",
            "Epoch 181 complete\n",
            "Epoch 182 complete\n",
            "Epoch 183 complete\n",
            "Epoch 184 complete\n",
            "Epoch 185 complete\n",
            "Epoch 186 complete\n",
            "Epoch 187 complete\n",
            "Epoch 188 complete\n",
            "Epoch 189 complete\n",
            "Epoch 190 complete\n",
            "Epoch 191 complete\n",
            "Epoch 192 complete\n",
            "Epoch 193 complete\n",
            "Epoch 194 complete\n",
            "Epoch 195 complete\n",
            "Epoch 196 complete\n",
            "Epoch 197 complete\n",
            "Epoch 198 complete\n",
            "Epoch 199 complete\n",
            "Epoch 200 complete\n",
            "Epoch 201 complete\n",
            "Epoch 202 complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KN2Qe58KCMHj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Predict and Report"
      ]
    },
    {
      "metadata": {
        "id": "A5E17jj1yGKz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# walk-forward validation on the test data\n",
        "predictions = list()\n",
        "for i in range(len(test_scaled)):\n",
        "  # make one-step forecast\n",
        "  X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
        "  yhat = forecast_lstm(lstm_model, 1, X)\n",
        "  # invert scaling\n",
        "  yhat = invert_scale(scaler, X, yhat)\n",
        "  # invert differencing\n",
        "  yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
        "  # store forecast\n",
        "  predictions.append(yhat)\n",
        "  expected = raw_values[len(train) + i + 1]\n",
        "  print('Predicted = $%d, Expected = $%d' % (yhat, expected))\n",
        "  \n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions))\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "# line plot of observed vs predicted\n",
        "pyplot.plot(raw_values[-len(test_scaled):], label = 'Expected')\n",
        "pyplot.plot(predictions, label = 'Predicted')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}